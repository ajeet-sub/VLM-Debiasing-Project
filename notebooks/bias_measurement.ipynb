{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/home/hice1/awagh31/scratch/miniconda3/envs/vlm-debiasing/lib/python3.12/site-packages')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Load the metadata CSV file\n",
    "metadata = pd.read_csv('/home/hice1/asubramanian91/scratch/e-daic/data/e-daic/undersampled_embeddings.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = []\n",
    "valid_indices = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multimodal Embeddings Shape: (210, 2236)\n"
     ]
    }
   ],
   "source": [
    "# Function to load an embedding from a file path\n",
    "def load_embedding(file_path):\n",
    "    if not os.path.exists(file_path):\n",
    "        raise FileNotFoundError(f\"Embedding file not found: {file_path}\")\n",
    "    return np.load(file_path, allow_pickle=True)\n",
    "\n",
    "# Iterate over each row in the metadata DataFrame\n",
    "for idx, row in metadata.iterrows():\n",
    "    try:\n",
    "        # Load embeddings for each modality\n",
    "        audio_emb = load_embedding(row['audio'])\n",
    "        visual_emb = load_embedding(row['visual'])\n",
    "        text_emb = load_embedding(row['text'])\n",
    "        \n",
    "        # Ensure all embeddings are 1-D arrays (flatten if necessary)\n",
    "        if audio_emb.ndim != 1:\n",
    "            audio_emb = audio_emb.flatten()\n",
    "        if visual_emb.ndim != 1:\n",
    "            visual_emb = visual_emb.flatten()\n",
    "        if text_emb.ndim != 1:\n",
    "            text_emb = text_emb.flatten()\n",
    "        \n",
    "        # Concatenate embeddings to form a multimodal embedding\n",
    "        multimodal_emb = np.concatenate([audio_emb, visual_emb, text_emb])\n",
    "        \n",
    "        # Append the concatenated embedding and index to the respective lists\n",
    "        embeddings.append(multimodal_emb)\n",
    "        valid_indices.append(idx)\n",
    "        \n",
    "    except (ValueError, IOError, FileNotFoundError) as e:\n",
    "        print(f\"Skipping index {idx} due to loading error: {e}\")\n",
    "\n",
    "# Convert the list of embeddings to a NumPy array for further processing\n",
    "if embeddings:\n",
    "    multimodal_embeddings_array = np.stack(embeddings)\n",
    "    print(f\"Multimodal Embeddings Shape: {multimodal_embeddings_array.shape}\")\n",
    "else:\n",
    "    print(\"No valid embeddings were loaded.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings_modified = [[sub[1:] for sub in embedding] for embedding in embeddings]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.vstack(multimodal_embeddings_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X: (210, 2236), Shape of y: (210,)\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    metadata_filtered = metadata.iloc[valid_indices]\n",
    "except IndexError:\n",
    "    print(\"Some indices in valid_indices are out-of-bounds for metadata. Check your filtering steps.\")\n",
    "\n",
    "# After filtering, extract the PTSD labels\n",
    "y = metadata_filtered['PTSD_label'].values\n",
    "\n",
    "# Verify that X and y have the same number of samples\n",
    "print(f\"Shape of X: {X.shape}, Shape of y: {y.shape}\")\n",
    "X = np.array(X)\n",
    "y = np.array(y)\n",
    "\n",
    "# Get the number of samples in each\n",
    "num_samples = min(X.shape[0], y.shape[0])\n",
    "\n",
    "# Truncate X and y to the same number of samples\n",
    "X_aligned = X[:num_samples]\n",
    "y_aligned = y[:num_samples]\n",
    "\n",
    "# Now proceed with train_test_split if the shapes match\n",
    "if X_aligned.shape[0] == y_aligned.shape[0]:\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_aligned, y_aligned, test_size=0.2, random_state=42)\n",
    "else:\n",
    "    print(\"Mismatch in the number of samples between X and y.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "if 'gender' in metadata.columns:\n",
    "    le = LabelEncoder()\n",
    "    metadata['gender'] = le.fit_transform(metadata['gender'])\n",
    "\n",
    "# Split the dataset into training and testing sets (80-20 split)\n",
    "#X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize and train the Random Forest classifier\n",
    "rf_model = RandomForestClassifier(n_estimators=50, random_state=42)\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred = rf_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6904761904761905\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.97      0.81        29\n",
      "           1       0.50      0.08      0.13        13\n",
      "\n",
      "    accuracy                           0.69        42\n",
      "   macro avg       0.60      0.52      0.47        42\n",
      "weighted avg       0.64      0.69      0.60        42\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: fairlearn in ./scratch/miniconda3/envs/vlmenv/lib/python3.12/site-packages (0.11.0)\n",
      "Requirement already satisfied: numpy>=1.24.4 in ./scratch/miniconda3/envs/vlmenv/lib/python3.12/site-packages (from fairlearn) (1.26.4)\n",
      "Requirement already satisfied: pandas>=2.0.3 in ./scratch/miniconda3/envs/vlmenv/lib/python3.12/site-packages (from fairlearn) (2.2.3)\n",
      "Requirement already satisfied: scikit-learn>=1.2.1 in ./scratch/miniconda3/envs/vlmenv/lib/python3.12/site-packages (from fairlearn) (1.5.1)\n",
      "Requirement already satisfied: scipy>=1.9.3 in ./scratch/miniconda3/envs/vlmenv/lib/python3.12/site-packages (from fairlearn) (1.14.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in ./scratch/miniconda3/envs/vlmenv/lib/python3.12/site-packages (from pandas>=2.0.3->fairlearn) (2.9.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in ./scratch/miniconda3/envs/vlmenv/lib/python3.12/site-packages (from pandas>=2.0.3->fairlearn) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in ./scratch/miniconda3/envs/vlmenv/lib/python3.12/site-packages (from pandas>=2.0.3->fairlearn) (2023.3)\n",
      "Requirement already satisfied: joblib>=1.2.0 in ./scratch/miniconda3/envs/vlmenv/lib/python3.12/site-packages (from scikit-learn>=1.2.1->fairlearn) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in ./scratch/miniconda3/envs/vlmenv/lib/python3.12/site-packages (from scikit-learn>=1.2.1->fairlearn) (3.5.0)\n",
      "Requirement already satisfied: six>=1.5 in ./scratch/miniconda3/envs/vlmenv/lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas>=2.0.3->fairlearn) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install fairlearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Participant</th>\n",
       "      <th>gender</th>\n",
       "      <th>split</th>\n",
       "      <th>PTSD_label</th>\n",
       "      <th>age</th>\n",
       "      <th>PTSD_severity</th>\n",
       "      <th>audio</th>\n",
       "      <th>text</th>\n",
       "      <th>visual</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>411</td>\n",
       "      <td>0</td>\n",
       "      <td>train</td>\n",
       "      <td>0</td>\n",
       "      <td>59</td>\n",
       "      <td>17.0</td>\n",
       "      <td>/home/hice1/asubramanian91/scratch/e-daic/data...</td>\n",
       "      <td>/home/hice1/asubramanian91/scratch/e-daic/data...</td>\n",
       "      <td>/home/hice1/asubramanian91/scratch/e-daic/data...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>353</td>\n",
       "      <td>0</td>\n",
       "      <td>train</td>\n",
       "      <td>1</td>\n",
       "      <td>35</td>\n",
       "      <td>55.0</td>\n",
       "      <td>/home/hice1/asubramanian91/scratch/e-daic/data...</td>\n",
       "      <td>/home/hice1/asubramanian91/scratch/e-daic/data...</td>\n",
       "      <td>/home/hice1/asubramanian91/scratch/e-daic/data...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>427</td>\n",
       "      <td>0</td>\n",
       "      <td>train</td>\n",
       "      <td>0</td>\n",
       "      <td>23</td>\n",
       "      <td>26.0</td>\n",
       "      <td>/home/hice1/asubramanian91/scratch/e-daic/data...</td>\n",
       "      <td>/home/hice1/asubramanian91/scratch/e-daic/data...</td>\n",
       "      <td>/home/hice1/asubramanian91/scratch/e-daic/data...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>402</td>\n",
       "      <td>0</td>\n",
       "      <td>dev</td>\n",
       "      <td>1</td>\n",
       "      <td>45</td>\n",
       "      <td>51.0</td>\n",
       "      <td>/home/hice1/asubramanian91/scratch/e-daic/data...</td>\n",
       "      <td>/home/hice1/asubramanian91/scratch/e-daic/data...</td>\n",
       "      <td>/home/hice1/asubramanian91/scratch/e-daic/data...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>374</td>\n",
       "      <td>0</td>\n",
       "      <td>dev</td>\n",
       "      <td>0</td>\n",
       "      <td>36</td>\n",
       "      <td>19.0</td>\n",
       "      <td>/home/hice1/asubramanian91/scratch/e-daic/data...</td>\n",
       "      <td>/home/hice1/asubramanian91/scratch/e-daic/data...</td>\n",
       "      <td>/home/hice1/asubramanian91/scratch/e-daic/data...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Participant  gender  split  PTSD_label  age  PTSD_severity  \\\n",
       "0          411       0  train           0   59           17.0   \n",
       "1          353       0  train           1   35           55.0   \n",
       "2          427       0  train           0   23           26.0   \n",
       "3          402       0    dev           1   45           51.0   \n",
       "4          374       0    dev           0   36           19.0   \n",
       "\n",
       "                                               audio  \\\n",
       "0  /home/hice1/asubramanian91/scratch/e-daic/data...   \n",
       "1  /home/hice1/asubramanian91/scratch/e-daic/data...   \n",
       "2  /home/hice1/asubramanian91/scratch/e-daic/data...   \n",
       "3  /home/hice1/asubramanian91/scratch/e-daic/data...   \n",
       "4  /home/hice1/asubramanian91/scratch/e-daic/data...   \n",
       "\n",
       "                                                text  \\\n",
       "0  /home/hice1/asubramanian91/scratch/e-daic/data...   \n",
       "1  /home/hice1/asubramanian91/scratch/e-daic/data...   \n",
       "2  /home/hice1/asubramanian91/scratch/e-daic/data...   \n",
       "3  /home/hice1/asubramanian91/scratch/e-daic/data...   \n",
       "4  /home/hice1/asubramanian91/scratch/e-daic/data...   \n",
       "\n",
       "                                              visual  \n",
       "0  /home/hice1/asubramanian91/scratch/e-daic/data...  \n",
       "1  /home/hice1/asubramanian91/scratch/e-daic/data...  \n",
       "2  /home/hice1/asubramanian91/scratch/e-daic/data...  \n",
       "3  /home/hice1/asubramanian91/scratch/e-daic/data...  \n",
       "4  /home/hice1/asubramanian91/scratch/e-daic/data...  "
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metadata.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of gender_test: (42,)\n",
      "Shape of y_test: (42,)\n",
      "Shape of y_pred: (42,)\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'numpy.ndarray' object has no attribute 'reset_index'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[45], line 12\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mShape of y_test: \u001b[39m\u001b[39m{\u001b[39;00my_test\u001b[39m.\u001b[39mshape\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     10\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mShape of y_pred: \u001b[39m\u001b[39m{\u001b[39;00my_pred\u001b[39m.\u001b[39mshape\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[0;32m---> 12\u001b[0m gender_test\u001b[39m.\u001b[39;49mreset_index(drop\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, inplace\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m     13\u001b[0m y_test \u001b[39m=\u001b[39m y_test\u001b[39m.\u001b[39mreset_index(drop\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m     14\u001b[0m y_pred \u001b[39m=\u001b[39m y_pred\u001b[39m.\u001b[39mreset_index(drop\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'numpy.ndarray' object has no attribute 'reset_index'"
     ]
    }
   ],
   "source": [
    "from fairlearn.metrics import demographic_parity_difference\n",
    "\n",
    "# Assuming `gender` corresponds to the original metadata\n",
    "# Split the dataset into training and testing sets for `gender`\n",
    "gender_train, gender_test = train_test_split(metadata['gender'].values, test_size=0.2, random_state=42)\n",
    "\n",
    "# Ensure that `gender_test`, `y_test`, and `y_pred` are aligned\n",
    "print(f\"Shape of gender_test: {gender_test.shape}\")\n",
    "print(f\"Shape of y_test: {y_test.shape}\")\n",
    "print(f\"Shape of y_pred: {y_pred.shape}\")\n",
    "\n",
    "# Calculate Demographic Parity Difference\n",
    "demographic_parity = demographic_parity_difference(\n",
    "    y_true=y_test,\n",
    "    y_pred=y_pred,\n",
    "    sensitive_features=gender_test\n",
    ")\n",
    "\n",
    "print(f\"Demographic Parity Difference: {demographic_parity}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'numpy' has no attribute 'matrix'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m~/scratch/miniconda3/envs/vlmenv/lib/python3.12/site-packages/pandas/core/indexes/base.py:3805\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3804\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 3805\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_engine\u001b[39m.\u001b[39;49mget_loc(casted_key)\n\u001b[1;32m   3806\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n",
      "File \u001b[0;32mindex.pyx:167\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mindex.pyx:196\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7081\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7089\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'sensitive_feature_0'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m~/scratch/miniconda3/envs/vlmenv/lib/python3.12/site-packages/pandas/core/frame.py:4485\u001b[0m, in \u001b[0;36mDataFrame._set_item_mgr\u001b[0;34m(self, key, value, refs)\u001b[0m\n\u001b[1;32m   4484\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 4485\u001b[0m     loc \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_info_axis\u001b[39m.\u001b[39;49mget_loc(key)\n\u001b[1;32m   4486\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m:\n\u001b[1;32m   4487\u001b[0m     \u001b[39m# This item wasn't present, just insert at end\u001b[39;00m\n",
      "File \u001b[0;32m~/scratch/miniconda3/envs/vlmenv/lib/python3.12/site-packages/pandas/core/indexes/base.py:3812\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3811\u001b[0m         \u001b[39mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[0;32m-> 3812\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(key) \u001b[39mfrom\u001b[39;00m \u001b[39merr\u001b[39;00m\n\u001b[1;32m   3813\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m:\n\u001b[1;32m   3814\u001b[0m     \u001b[39m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[1;32m   3815\u001b[0m     \u001b[39m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[1;32m   3816\u001b[0m     \u001b[39m#  the TypeError.\u001b[39;00m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'sensitive_feature_0'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[33], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mfairlearn\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmetrics\u001b[39;00m \u001b[39mimport\u001b[39;00m MetricFrame, selection_rate\n\u001b[0;32m----> 2\u001b[0m metric_frame \u001b[39m=\u001b[39m MetricFrame(metrics\u001b[39m=\u001b[39;49mselection_rate, \n\u001b[1;32m      3\u001b[0m                            y_true\u001b[39m=\u001b[39;49my_test, \n\u001b[1;32m      4\u001b[0m                            y_pred\u001b[39m=\u001b[39;49my_pred, \n\u001b[1;32m      5\u001b[0m                            sensitive_features\u001b[39m=\u001b[39;49mgender_test)\n\u001b[1;32m      7\u001b[0m \u001b[39m# Get selection rates for each group\u001b[39;00m\n\u001b[1;32m      8\u001b[0m selection_rates \u001b[39m=\u001b[39m metric_frame\u001b[39m.\u001b[39mby_group\n",
      "File \u001b[0;32m~/scratch/miniconda3/envs/vlmenv/lib/python3.12/site-packages/fairlearn/metrics/_metric_frame.py:256\u001b[0m, in \u001b[0;36mMetricFrame.__init__\u001b[0;34m(self, metrics, y_true, y_pred, sensitive_features, control_features, sample_params, n_boot, ci_quantiles, random_state)\u001b[0m\n\u001b[1;32m    254\u001b[0m \u001b[39m# Add sensitive and conditional features to all_data\u001b[39;00m\n\u001b[1;32m    255\u001b[0m \u001b[39mfor\u001b[39;00m sf \u001b[39min\u001b[39;00m sf_list:\n\u001b[0;32m--> 256\u001b[0m     all_data[sf\u001b[39m.\u001b[39;49mname_] \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(sf\u001b[39m.\u001b[39mraw_feature_)\n\u001b[1;32m    257\u001b[0m \u001b[39mif\u001b[39;00m cf_list \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    258\u001b[0m     \u001b[39mfor\u001b[39;00m cf \u001b[39min\u001b[39;00m cf_list:\n",
      "File \u001b[0;32m~/scratch/miniconda3/envs/vlmenv/lib/python3.12/site-packages/pandas/core/frame.py:4311\u001b[0m, in \u001b[0;36mDataFrame.__setitem__\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m   4308\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_setitem_array([key], value)\n\u001b[1;32m   4309\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   4310\u001b[0m     \u001b[39m# set column\u001b[39;00m\n\u001b[0;32m-> 4311\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_set_item(key, value)\n",
      "File \u001b[0;32m~/scratch/miniconda3/envs/vlmenv/lib/python3.12/site-packages/pandas/core/frame.py:4538\u001b[0m, in \u001b[0;36mDataFrame._set_item\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m   4535\u001b[0m             value \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mtile(value, (\u001b[39mlen\u001b[39m(existing_piece\u001b[39m.\u001b[39mcolumns), \u001b[39m1\u001b[39m))\u001b[39m.\u001b[39mT\n\u001b[1;32m   4536\u001b[0m             refs \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m-> 4538\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_set_item_mgr(key, value, refs)\n",
      "File \u001b[0;32m~/scratch/miniconda3/envs/vlmenv/lib/python3.12/site-packages/pandas/core/frame.py:4488\u001b[0m, in \u001b[0;36mDataFrame._set_item_mgr\u001b[0;34m(self, key, value, refs)\u001b[0m\n\u001b[1;32m   4485\u001b[0m     loc \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_info_axis\u001b[39m.\u001b[39mget_loc(key)\n\u001b[1;32m   4486\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m:\n\u001b[1;32m   4487\u001b[0m     \u001b[39m# This item wasn't present, just insert at end\u001b[39;00m\n\u001b[0;32m-> 4488\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_mgr\u001b[39m.\u001b[39;49minsert(\u001b[39mlen\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_info_axis), key, value, refs)\n\u001b[1;32m   4489\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   4490\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_iset_item_mgr(loc, value, refs\u001b[39m=\u001b[39mrefs)\n",
      "File \u001b[0;32m~/scratch/miniconda3/envs/vlmenv/lib/python3.12/site-packages/pandas/core/internals/managers.py:1385\u001b[0m, in \u001b[0;36mBlockManager.insert\u001b[0;34m(self, loc, item, value, refs)\u001b[0m\n\u001b[1;32m   1383\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1384\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_insert_update_mgr_locs(loc)\n\u001b[0;32m-> 1385\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_insert_update_blklocs_and_blknos(loc)\n\u001b[1;32m   1387\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39maxes[\u001b[39m0\u001b[39m] \u001b[39m=\u001b[39m new_axis\n\u001b[1;32m   1388\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mblocks \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m (block,)\n",
      "File \u001b[0;32m~/scratch/miniconda3/envs/vlmenv/lib/python3.12/site-packages/pandas/core/internals/managers.py:1421\u001b[0m, in \u001b[0;36mBlockManager._insert_update_blklocs_and_blknos\u001b[0;34m(self, loc)\u001b[0m\n\u001b[1;32m   1418\u001b[0m \u001b[39m# Accessing public blklocs ensures the public versions are initialized\u001b[39;00m\n\u001b[1;32m   1419\u001b[0m \u001b[39mif\u001b[39;00m loc \u001b[39m==\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mblklocs\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m]:\n\u001b[1;32m   1420\u001b[0m     \u001b[39m# np.append is a lot faster, let's use it if we can.\u001b[39;00m\n\u001b[0;32m-> 1421\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_blklocs \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39;49mappend(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_blklocs, \u001b[39m0\u001b[39;49m)\n\u001b[1;32m   1422\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_blknos \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mappend(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_blknos, \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mblocks))\n\u001b[1;32m   1423\u001b[0m \u001b[39melif\u001b[39;00m loc \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m   1424\u001b[0m     \u001b[39m# np.append is a lot faster, let's use it if we can.\u001b[39;00m\n",
      "File \u001b[0;32m~/scratch/miniconda3/envs/vlmenv/lib/python3.12/site-packages/numpy/lib/function_base.py:5616\u001b[0m, in \u001b[0;36mappend\u001b[0;34m(arr, values, axis)\u001b[0m\n\u001b[1;32m   5614\u001b[0m     \u001b[39mif\u001b[39;00m arr\u001b[39m.\u001b[39mndim \u001b[39m!=\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m   5615\u001b[0m         arr \u001b[39m=\u001b[39m arr\u001b[39m.\u001b[39mravel()\n\u001b[0;32m-> 5616\u001b[0m     values \u001b[39m=\u001b[39m ravel(values)\n\u001b[1;32m   5617\u001b[0m     axis \u001b[39m=\u001b[39m arr\u001b[39m.\u001b[39mndim\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m\n\u001b[1;32m   5618\u001b[0m \u001b[39mreturn\u001b[39;00m concatenate((arr, values), axis\u001b[39m=\u001b[39maxis)\n",
      "File \u001b[0;32m~/scratch/miniconda3/envs/vlmenv/lib/python3.12/site-packages/numpy/core/fromnumeric.py:1871\u001b[0m, in \u001b[0;36mravel\u001b[0;34m(a, order)\u001b[0m\n\u001b[1;32m   1768\u001b[0m \u001b[39m@array_function_dispatch\u001b[39m(_ravel_dispatcher)\n\u001b[1;32m   1769\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mravel\u001b[39m(a, order\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mC\u001b[39m\u001b[39m'\u001b[39m):\n\u001b[1;32m   1770\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Return a contiguous flattened array.\u001b[39;00m\n\u001b[1;32m   1771\u001b[0m \n\u001b[1;32m   1772\u001b[0m \u001b[39m    A 1-D array, containing the elements of the input, is returned.  A copy is\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1869\u001b[0m \n\u001b[1;32m   1870\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1871\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(a, np\u001b[39m.\u001b[39;49mmatrix):\n\u001b[1;32m   1872\u001b[0m         \u001b[39mreturn\u001b[39;00m asarray(a)\u001b[39m.\u001b[39mravel(order\u001b[39m=\u001b[39morder)\n\u001b[1;32m   1873\u001b[0m     \u001b[39melse\u001b[39;00m:\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'numpy' has no attribute 'matrix'"
     ]
    }
   ],
   "source": [
    "from fairlearn.metrics import MetricFrame, selection_rate\n",
    "metric_frame = MetricFrame(metrics=selection_rate, \n",
    "                           y_true=y_test, \n",
    "                           y_pred=y_pred, \n",
    "                           sensitive_features=gender_test)\n",
    "\n",
    "# Get selection rates for each group\n",
    "selection_rates = metric_frame.by_group\n",
    "print(\"Selection Rates by Group:\")\n",
    "print(selection_rates)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Demographic Parity Ratio: 0.4473684210526316\n"
     ]
    }
   ],
   "source": [
    "group_a_rate = selection_rates[1]\n",
    "group_b_rate = selection_rates[0]\n",
    "\n",
    "if group_b_rate > 0:  # Avoid division by zero\n",
    "    demographic_parity_ratio = group_a_rate / group_b_rate\n",
    "    print(f\"Demographic Parity Ratio: {demographic_parity_ratio}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
