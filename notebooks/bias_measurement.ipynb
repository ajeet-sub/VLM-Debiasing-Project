{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/home/hice1/awagh31/scratch/miniconda3/envs/vlm-debiasing/lib/python3.12/site-packages')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/942792/ipykernel_1303103/1805313894.py:1: DeprecationWarning: \n",
      "Pyarrow will become a required dependency of pandas in the next major release of pandas (pandas 3.0),\n",
      "(to allow more performant data types, such as the Arrow string type, and better interoperability with other libraries)\n",
      "but was not found to be installed on your system.\n",
      "If this would cause problems for you,\n",
      "please provide us feedback at https://github.com/pandas-dev/pandas/issues/54466\n",
      "        \n",
      "  import pandas as pd\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Load the metadata CSV file\n",
    "metadata = pd.read_csv('/home/hice1/awagh31/scratch/scripts/labels_visual_files_dn.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = []\n",
    "valid_indices = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#folder containing npy files\n",
    "npy_base_dir = '/home/hice1/awagh31/scratch/final_embeddings_dn/features' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping /home/hice1/awagh31/scratch/final_embeddings_dn/features/609_densenet201/609_densenet201.npy due to loading error.\n"
     ]
    }
   ],
   "source": [
    "for idx, csv_path in enumerate(metadata['file_path']):\n",
    "    try:\n",
    "        \n",
    "        filename = os.path.basename(csv_path).replace('.csv', '')\n",
    "        #print(filename)\n",
    "        # Construct the expected path to the corresponding .npy file\n",
    "        #change these lines if required, basically npy_path should be the path to each npy file\n",
    "        npy_path = os.path.join(npy_base_dir, filename, f\"{filename}.npy\") \n",
    "        #print(npy_path)\n",
    "        embedding = np.load(npy_path, allow_pickle=True) \n",
    "         # Assuming embeddings are stored as .npy files\n",
    "        #embedding_standardized = standardize_embedding(embedding, standard_dim)\n",
    "        #print(npy_path, embedding.shape)\n",
    "        #embedding_reduced = pca.fit_transform(embedding.reshape(1, -1)).flatten()\n",
    "        embeddings.append(embedding)\n",
    "        valid_indices.append(idx)\n",
    "    except (ValueError, IOError):\n",
    "        print(f\"Skipping {npy_path} due to loading error.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings_modified = [[sub[1:] for sub in embedding] for embedding in embeddings]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.vstack(embeddings_modified)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X: (260909, 1921), Shape of y: (274,)\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    metadata_filtered = metadata.iloc[valid_indices]\n",
    "except IndexError:\n",
    "    print(\"Some indices in valid_indices are out-of-bounds for metadata. Check your filtering steps.\")\n",
    "\n",
    "# After filtering, extract the PTSD labels\n",
    "y = metadata_filtered['PTSD_label'].values\n",
    "\n",
    "# Verify that X and y have the same number of samples\n",
    "print(f\"Shape of X: {X.shape}, Shape of y: {y.shape}\")\n",
    "X = np.array(X)\n",
    "y = np.array(y)\n",
    "\n",
    "# Get the number of samples in each\n",
    "num_samples = min(X.shape[0], y.shape[0])\n",
    "\n",
    "# Truncate X and y to the same number of samples\n",
    "X_aligned = X[:num_samples]\n",
    "y_aligned = y[:num_samples]\n",
    "\n",
    "# Now proceed with train_test_split if the shapes match\n",
    "if X_aligned.shape[0] == y_aligned.shape[0]:\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_aligned, y_aligned, test_size=0.2, random_state=42)\n",
    "else:\n",
    "    print(\"Mismatch in the number of samples between X and y.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "if 'gender' in metadata.columns:\n",
    "    le = LabelEncoder()\n",
    "    metadata['gender'] = le.fit_transform(metadata['gender'])\n",
    "\n",
    "# Split the dataset into training and testing sets (80-20 split)\n",
    "#X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize and train the Random Forest classifier\n",
    "rf_model = RandomForestClassifier(n_estimators=50, random_state=42)\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred = rf_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7454545454545455\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.98      0.85        41\n",
      "           1       0.50      0.07      0.12        14\n",
      "\n",
      "    accuracy                           0.75        55\n",
      "   macro avg       0.63      0.52      0.49        55\n",
      "weighted avg       0.69      0.75      0.67        55\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: fairlearn in /home/hice1/awagh31/.local/lib/python3.10/site-packages (0.11.0)\n",
      "Requirement already satisfied: scikit-learn>=1.2.1 in /storage/pace-apps/manual/packages/anaconda3/2023.03/lib/python3.10/site-packages (from fairlearn) (1.2.2)\n",
      "Requirement already satisfied: pandas>=2.0.3 in /storage/pace-apps/manual/packages/anaconda3/2023.03/lib/python3.10/site-packages (from fairlearn) (2.2.0)\n",
      "Requirement already satisfied: numpy>=1.24.4 in /home/hice1/awagh31/.local/lib/python3.10/site-packages (from fairlearn) (1.26.4)\n",
      "Requirement already satisfied: scipy>=1.9.3 in /storage/pace-apps/manual/packages/anaconda3/2023.03/lib/python3.10/site-packages (from fairlearn) (1.10.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /storage/pace-apps/manual/packages/anaconda3/2023.03/lib/python3.10/site-packages (from pandas>=2.0.3->fairlearn) (2023.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /storage/pace-apps/manual/packages/anaconda3/2023.03/lib/python3.10/site-packages (from pandas>=2.0.3->fairlearn) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /storage/pace-apps/manual/packages/anaconda3/2023.03/lib/python3.10/site-packages (from pandas>=2.0.3->fairlearn) (2022.7)\n",
      "Requirement already satisfied: joblib>=1.1.1 in /storage/pace-apps/manual/packages/anaconda3/2023.03/lib/python3.10/site-packages (from scikit-learn>=1.2.1->fairlearn) (1.2.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /storage/pace-apps/manual/packages/anaconda3/2023.03/lib/python3.10/site-packages (from scikit-learn>=1.2.1->fairlearn) (2.2.0)\n",
      "Requirement already satisfied: six>=1.5 in /storage/pace-apps/manual/packages/anaconda3/2023.03/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas>=2.0.3->fairlearn) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install fairlearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gender</th>\n",
       "      <th>split</th>\n",
       "      <th>PTSD_label</th>\n",
       "      <th>age</th>\n",
       "      <th>PTSD_severity</th>\n",
       "      <th>file_path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>train</td>\n",
       "      <td>0</td>\n",
       "      <td>45</td>\n",
       "      <td>22.0</td>\n",
       "      <td>/home/hice1/awagh31/scratch/original/data_unta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>test</td>\n",
       "      <td>0</td>\n",
       "      <td>69</td>\n",
       "      <td>23.0</td>\n",
       "      <td>/home/hice1/awagh31/scratch/original/data_unta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>train</td>\n",
       "      <td>0</td>\n",
       "      <td>25</td>\n",
       "      <td>19.0</td>\n",
       "      <td>/home/hice1/awagh31/scratch/original/data_unta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>train</td>\n",
       "      <td>1</td>\n",
       "      <td>58</td>\n",
       "      <td>67.0</td>\n",
       "      <td>/home/hice1/awagh31/scratch/original/data_unta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>dev</td>\n",
       "      <td>0</td>\n",
       "      <td>33</td>\n",
       "      <td>39.0</td>\n",
       "      <td>/home/hice1/awagh31/scratch/original/data_unta...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   gender  split  PTSD_label  age  PTSD_severity  \\\n",
       "0       0  train           0   45           22.0   \n",
       "1       1   test           0   69           23.0   \n",
       "2       1  train           0   25           19.0   \n",
       "3       0  train           1   58           67.0   \n",
       "4       1    dev           0   33           39.0   \n",
       "\n",
       "                                           file_path  \n",
       "0  /home/hice1/awagh31/scratch/original/data_unta...  \n",
       "1  /home/hice1/awagh31/scratch/original/data_unta...  \n",
       "2  /home/hice1/awagh31/scratch/original/data_unta...  \n",
       "3  /home/hice1/awagh31/scratch/original/data_unta...  \n",
       "4  /home/hice1/awagh31/scratch/original/data_unta...  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metadata.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of gender_test: (55,)\n",
      "Shape of y_test: (55,)\n",
      "Shape of y_pred: (55,)\n",
      "Demographic Parity Difference: 0.032507739938080496\n"
     ]
    }
   ],
   "source": [
    "from fairlearn.metrics import demographic_parity_difference\n",
    "\n",
    "# Assuming `gender` corresponds to the original metadata\n",
    "# Split the dataset into training and testing sets for `gender`\n",
    "gender_train, gender_test = train_test_split(metadata['gender'].values, test_size=0.2, random_state=42)\n",
    "\n",
    "# Ensure that `gender_test`, `y_test`, and `y_pred` are aligned\n",
    "print(f\"Shape of gender_test: {gender_test.shape}\")\n",
    "print(f\"Shape of y_test: {y_test.shape}\")\n",
    "print(f\"Shape of y_pred: {y_pred.shape}\")\n",
    "\n",
    "# Calculate Demographic Parity Difference\n",
    "demographic_parity = demographic_parity_difference(\n",
    "    y_true=y_test,\n",
    "    y_pred=y_pred,\n",
    "    sensitive_features=gender_test\n",
    ")\n",
    "\n",
    "print(f\"Demographic Parity Difference: {demographic_parity}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selection Rates by Group:\n",
      "sensitive_feature_0\n",
      "0    0.058824\n",
      "1    0.026316\n",
      "Name: selection_rate, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "from fairlearn.metrics import MetricFrame, selection_rate\n",
    "metric_frame = MetricFrame(metrics=selection_rate, \n",
    "                           y_true=y_test, \n",
    "                           y_pred=y_pred, \n",
    "                           sensitive_features=gender_test)\n",
    "\n",
    "# Get selection rates for each group\n",
    "selection_rates = metric_frame.by_group\n",
    "print(\"Selection Rates by Group:\")\n",
    "print(selection_rates)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Demographic Parity Ratio: 0.4473684210526316\n"
     ]
    }
   ],
   "source": [
    "group_a_rate = selection_rates[1]\n",
    "group_b_rate = selection_rates[0]\n",
    "\n",
    "if group_b_rate > 0:  # Avoid division by zero\n",
    "    demographic_parity_ratio = group_a_rate / group_b_rate\n",
    "    print(f\"Demographic Parity Ratio: {demographic_parity_ratio}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
