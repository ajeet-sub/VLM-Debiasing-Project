{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/home/hice1/mbibars3/scratch/vlm-debiasing/VLM-Debiasing-Project/scripts')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "%autoreload 2\n",
    "import model as m\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import loaders\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training model on dummy data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 768, 1])\n",
      "Output shape: torch.Size([10, 1])\n"
     ]
    }
   ],
   "source": [
    "# Assuming MultiModalPerceiver is defined as in the code above\n",
    "# Define input dimensions for each modality\n",
    "input_dims = [64, 128, 256]  # These could be the feature dimensions for each modality\n",
    "\n",
    "# Initialize MultiModalPerceiver model\n",
    "model = m.MultiModalPerceiver(\n",
    "    input_dims=input_dims,\n",
    "    input_channels=1,\n",
    "    input_axis=1,\n",
    "    projection_dim=256,\n",
    "    num_latents=16,\n",
    "    latent_dim=128,\n",
    "    depth=8,\n",
    "    cross_heads=8,\n",
    "    latent_heads=8,\n",
    "    cross_dim_head=32,\n",
    "    latent_dim_head=32,\n",
    "    attn_dropout=0.1,\n",
    "    ff_dropout=0.0,\n",
    "    output_dim=1,\n",
    "    weight_tie_layers=True,\n",
    "    fourier_encode_data=False,\n",
    "    max_freq=10,\n",
    "    num_freq_bands=4\n",
    ")\n",
    "\n",
    "# Create random data for each modality\n",
    "batch_size = 10  # Number of samples in a batch\n",
    "modality_1 = torch.randn(batch_size, input_dims[0])  # First modality with input dimension 64\n",
    "modality_2 = torch.randn(batch_size, input_dims[1])  # Second modality with input dimension 128\n",
    "modality_3 = torch.randn(batch_size, input_dims[2])  # Third modality with input dimension 256\n",
    "\n",
    "# Combine modalities into a list and pass through the model\n",
    "input_data = [modality_1, modality_2, modality_3]\n",
    "output = model(input_data)\n",
    "\n",
    "# Print output shape to verify\n",
    "print(\"Output shape:\", output.shape)  # Expected shape: [batch_size, output_dim]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-1.0926],\n",
      "        [-1.1314],\n",
      "        [-1.0889],\n",
      "        [-1.1205],\n",
      "        [-1.0704],\n",
      "        [-1.0984],\n",
      "        [-1.0807],\n",
      "        [-1.0941],\n",
      "        [-1.1047],\n",
      "        [-1.1045]], grad_fn=<AddmmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/5], Loss: 2.0485\n",
      "Epoch [2/5], Loss: 16.5415\n",
      "Epoch [3/5], Loss: 3.2676\n",
      "Epoch [4/5], Loss: 1.2193\n",
      "Epoch [5/5], Loss: 2.2094\n"
     ]
    }
   ],
   "source": [
    "# Dummy target output (regression target)\n",
    "target = torch.randn(batch_size, 1)  # Shape: [batch_size, output_dim]\n",
    "\n",
    "learning_rate = 0.001\n",
    "num_epochs = 5\n",
    "# Define loss function and optimizer\n",
    "criterion = nn.MSELoss()  # Mean Squared Error for regression\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(num_epochs):\n",
    "    # Zero the parameter gradients\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    # Forward pass\n",
    "    inputs = [modality_1, modality_2, modality_3]\n",
    "    output = model(inputs)\n",
    "    \n",
    "    # Compute loss\n",
    "    loss = criterion(output, target)\n",
    "    \n",
    "    # Backward pass and optimize\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    # Print loss\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(768, 1)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "arr = np.load('/home/hice1/mbibars3/scratch/vlm-debiasing/data/e-daic/untarred/717_P/717_AUDIO_ast9_pooled.npy')\n",
    "arr.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building the dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dummy data created and saved to 'dummy_data' folder.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# Define paths for saving the dummy data\n",
    "os.makedirs(\"dummy_data\", exist_ok=True)\n",
    "\n",
    "# Generate dummy data and save it to .npy files\n",
    "num_samples = 10\n",
    "feature_size = 5\n",
    "\n",
    "data = {\n",
    "    \"label\": [],\n",
    "    \"modality1_path\": [],\n",
    "    \"modality2_path\": [],\n",
    "    \"modality3_path\": []\n",
    "}\n",
    "\n",
    "for i in range(num_samples):\n",
    "    # Create dummy numpy arrays of shape (feature, 1)\n",
    "    modality1 = np.random.rand(feature_size, 1)\n",
    "    modality2 = np.random.rand(feature_size, 1)\n",
    "    modality3 = np.random.rand(feature_size, 1)\n",
    "\n",
    "    # Save each modality to a separate file\n",
    "    modality1_path = f\"dummy_data/modality1_sample{i}.npy\"\n",
    "    modality2_path = f\"dummy_data/modality2_sample{i}.npy\"\n",
    "    modality3_path = f\"dummy_data/modality3_sample{i}.npy\"\n",
    "    np.save(modality1_path, modality1)\n",
    "    np.save(modality2_path, modality2)\n",
    "    np.save(modality3_path, modality3)\n",
    "    \n",
    "    # Populate data for the DataFrame\n",
    "    data[\"label\"].append(np.random.randint(0, 2))  # Random label (0 or 1)\n",
    "    data[\"modality1_path\"].append(modality1_path)\n",
    "    data[\"modality2_path\"].append(modality2_path)\n",
    "    data[\"modality3_path\"].append(modality3_path)\n",
    "\n",
    "# Create the DataFrame\n",
    "import pandas as pd\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Save the DataFrame to a CSV for reference (optional)\n",
    "df.to_csv(\"dummy_data/data.csv\", index=False)\n",
    "\n",
    "print(\"Dummy data created and saved to 'dummy_data' folder.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>modality1_path</th>\n",
       "      <th>modality2_path</th>\n",
       "      <th>modality3_path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>dummy_data/modality1_sample0.npy</td>\n",
       "      <td>dummy_data/modality2_sample0.npy</td>\n",
       "      <td>dummy_data/modality3_sample0.npy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>dummy_data/modality1_sample1.npy</td>\n",
       "      <td>dummy_data/modality2_sample1.npy</td>\n",
       "      <td>dummy_data/modality3_sample1.npy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>dummy_data/modality1_sample2.npy</td>\n",
       "      <td>dummy_data/modality2_sample2.npy</td>\n",
       "      <td>dummy_data/modality3_sample2.npy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>dummy_data/modality1_sample3.npy</td>\n",
       "      <td>dummy_data/modality2_sample3.npy</td>\n",
       "      <td>dummy_data/modality3_sample3.npy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>dummy_data/modality1_sample4.npy</td>\n",
       "      <td>dummy_data/modality2_sample4.npy</td>\n",
       "      <td>dummy_data/modality3_sample4.npy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>dummy_data/modality1_sample5.npy</td>\n",
       "      <td>dummy_data/modality2_sample5.npy</td>\n",
       "      <td>dummy_data/modality3_sample5.npy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>dummy_data/modality1_sample6.npy</td>\n",
       "      <td>dummy_data/modality2_sample6.npy</td>\n",
       "      <td>dummy_data/modality3_sample6.npy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>dummy_data/modality1_sample7.npy</td>\n",
       "      <td>dummy_data/modality2_sample7.npy</td>\n",
       "      <td>dummy_data/modality3_sample7.npy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>dummy_data/modality1_sample8.npy</td>\n",
       "      <td>dummy_data/modality2_sample8.npy</td>\n",
       "      <td>dummy_data/modality3_sample8.npy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>dummy_data/modality1_sample9.npy</td>\n",
       "      <td>dummy_data/modality2_sample9.npy</td>\n",
       "      <td>dummy_data/modality3_sample9.npy</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label                    modality1_path                    modality2_path  \\\n",
       "0      1  dummy_data/modality1_sample0.npy  dummy_data/modality2_sample0.npy   \n",
       "1      1  dummy_data/modality1_sample1.npy  dummy_data/modality2_sample1.npy   \n",
       "2      1  dummy_data/modality1_sample2.npy  dummy_data/modality2_sample2.npy   \n",
       "3      1  dummy_data/modality1_sample3.npy  dummy_data/modality2_sample3.npy   \n",
       "4      0  dummy_data/modality1_sample4.npy  dummy_data/modality2_sample4.npy   \n",
       "5      0  dummy_data/modality1_sample5.npy  dummy_data/modality2_sample5.npy   \n",
       "6      1  dummy_data/modality1_sample6.npy  dummy_data/modality2_sample6.npy   \n",
       "7      0  dummy_data/modality1_sample7.npy  dummy_data/modality2_sample7.npy   \n",
       "8      1  dummy_data/modality1_sample8.npy  dummy_data/modality2_sample8.npy   \n",
       "9      0  dummy_data/modality1_sample9.npy  dummy_data/modality2_sample9.npy   \n",
       "\n",
       "                     modality3_path  \n",
       "0  dummy_data/modality3_sample0.npy  \n",
       "1  dummy_data/modality3_sample1.npy  \n",
       "2  dummy_data/modality3_sample2.npy  \n",
       "3  dummy_data/modality3_sample3.npy  \n",
       "4  dummy_data/modality3_sample4.npy  \n",
       "5  dummy_data/modality3_sample5.npy  \n",
       "6  dummy_data/modality3_sample6.npy  \n",
       "7  dummy_data/modality3_sample7.npy  \n",
       "8  dummy_data/modality3_sample8.npy  \n",
       "9  dummy_data/modality3_sample9.npy  "
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"dummy_data/data.csv\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modality 1 shape: torch.Size([2, 5, 1])\n",
      "Modality 2 shape: torch.Size([2, 5, 1])\n",
      "Modality 3 shape: torch.Size([2, 5, 1])\n",
      "Labels shape: tensor([1., 1.])\n",
      "Modality 1 shape: torch.Size([2, 5, 1])\n",
      "Modality 2 shape: torch.Size([2, 5, 1])\n",
      "Modality 3 shape: torch.Size([2, 5, 1])\n",
      "Labels shape: tensor([1., 1.])\n",
      "Modality 1 shape: torch.Size([2, 5, 1])\n",
      "Modality 2 shape: torch.Size([2, 5, 1])\n",
      "Modality 3 shape: torch.Size([2, 5, 1])\n",
      "Labels shape: tensor([0., 0.])\n",
      "Modality 1 shape: torch.Size([2, 5, 1])\n",
      "Modality 2 shape: torch.Size([2, 5, 1])\n",
      "Modality 3 shape: torch.Size([2, 5, 1])\n",
      "Labels shape: tensor([1., 0.])\n",
      "Modality 1 shape: torch.Size([2, 5, 1])\n",
      "Modality 2 shape: torch.Size([2, 5, 1])\n",
      "Modality 3 shape: torch.Size([2, 5, 1])\n",
      "Labels shape: tensor([1., 0.])\n"
     ]
    }
   ],
   "source": [
    "dataset = loaders.MultiModalityDataset(df)\n",
    "dataloader = DataLoader(dataset, batch_size=2, collate_fn=loaders.collate_fn)\n",
    "\n",
    "for batch in dataloader:\n",
    "    modalities, labels = batch\n",
    "    print(f\"Modality 1 shape: {modalities[0].shape}\")  # Expected shape: (batch_size, feature, 1)\n",
    "    print(f\"Modality 2 shape: {modalities[1].shape}\")\n",
    "    print(f\"Modality 3 shape: {modalities[2].shape}\")\n",
    "    print(f\"Labels shape: {labels}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming MultiModalPerceiver is defined as in the code above\n",
    "# Define input dimensions for each modality\n",
    "input_dims = [5, 5, 5]  # These could be the feature dimensions for each modality\n",
    "\n",
    "# Initialize MultiModalPerceiver model\n",
    "model = m.MultiModalPerceiver(\n",
    "    input_dims=input_dims,\n",
    "    input_channels=1,\n",
    "    input_axis=1,\n",
    "    projection_dim=256,\n",
    "    num_latents=16,\n",
    "    latent_dim=128,\n",
    "    depth=8,\n",
    "    cross_heads=8,\n",
    "    latent_heads=8,\n",
    "    cross_dim_head=32,\n",
    "    latent_dim_head=32,\n",
    "    attn_dropout=0.1,\n",
    "    ff_dropout=0.0,\n",
    "    output_dim=1,\n",
    "    weight_tie_layers=True,\n",
    "    fourier_encode_data=False,\n",
    "    max_freq=10,\n",
    "    num_freq_bands=4\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/5], Loss: 0.2971\n",
      "Epoch [1/5], Loss: 0.0045\n",
      "Epoch [1/5], Loss: 1.9311\n",
      "Epoch [1/5], Loss: 0.6432\n",
      "Epoch [1/5], Loss: 0.3425\n",
      "Epoch [2/5], Loss: 0.2707\n",
      "Epoch [2/5], Loss: 0.4511\n",
      "Epoch [2/5], Loss: 0.1029\n",
      "Epoch [2/5], Loss: 0.3046\n",
      "Epoch [2/5], Loss: 0.3107\n",
      "Epoch [3/5], Loss: 0.5261\n",
      "Epoch [3/5], Loss: 0.3862\n",
      "Epoch [3/5], Loss: 0.2883\n",
      "Epoch [3/5], Loss: 0.2622\n",
      "Epoch [3/5], Loss: 0.2760\n",
      "Epoch [4/5], Loss: 0.0971\n",
      "Epoch [4/5], Loss: 0.0646\n",
      "Epoch [4/5], Loss: 0.6814\n",
      "Epoch [4/5], Loss: 0.3420\n",
      "Epoch [4/5], Loss: 0.3155\n",
      "Epoch [5/5], Loss: 0.0973\n",
      "Epoch [5/5], Loss: 0.1173\n",
      "Epoch [5/5], Loss: 0.4393\n",
      "Epoch [5/5], Loss: 0.2623\n",
      "Epoch [5/5], Loss: 0.2522\n"
     ]
    }
   ],
   "source": [
    "learning_rate = 0.001\n",
    "num_epochs = 5\n",
    "# Define loss function and optimizer\n",
    "criterion = nn.MSELoss()  # Mean Squared Error for regression\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(num_epochs):\n",
    "    for batch in dataloader:\n",
    "        # Unpack the batch\n",
    "        modalities, labels = batch\n",
    "        modality_1, modality_2, modality_3 = modalities  # Each has shape (batch_size, feature, 1)\n",
    "\n",
    "        # Zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward pass\n",
    "        inputs = [modality_1, modality_2, modality_3]\n",
    "        output = model(inputs)\n",
    "\n",
    "        #print(output, labels)\n",
    "        # Reshape labels to match the output shape if necessary\n",
    "        labels = labels.view(output.shape)  # Ensures labels has shape (batch_size, 1)\n",
    "\n",
    "        # Compute loss\n",
    "        loss = criterion(output, labels)\n",
    "\n",
    "        # Backward pass and optimize\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Print loss\n",
    "        print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
