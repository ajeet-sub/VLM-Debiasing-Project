{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/home/hice1/mbibars3/scratch/vlm-debiasing/VLM-Debiasing-Project/scripts')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%autoreload 2\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import model as m\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import loaders\n",
    "from torch.utils.data import Dataset, DataLoader\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check model training on random arrays "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 768, 1])\n",
      "Output shape: torch.Size([10, 1])\n"
     ]
    }
   ],
   "source": [
    "# Assuming MultiModalPerceiver is defined as in the code above\n",
    "# Define input dimensions for each modality\n",
    "input_dims = [64, 128, 256]  # These could be the feature dimensions for each modality\n",
    "\n",
    "# Initialize MultiModalPerceiver model\n",
    "model = m.MultiModalPerceiver(\n",
    "    input_dims=input_dims,\n",
    "    input_channels=1,\n",
    "    input_axis=1,\n",
    "    projection_dim=256,\n",
    "    num_latents=16,\n",
    "    latent_dim=128,\n",
    "    depth=8,\n",
    "    cross_heads=8,\n",
    "    latent_heads=8,\n",
    "    cross_dim_head=32,\n",
    "    latent_dim_head=32,\n",
    "    attn_dropout=0.1,\n",
    "    ff_dropout=0.0,\n",
    "    output_dim=1,\n",
    "    weight_tie_layers=True,\n",
    "    fourier_encode_data=False,\n",
    "    max_freq=10,\n",
    "    num_freq_bands=4\n",
    ")\n",
    "\n",
    "# Create random data for each modality\n",
    "batch_size = 10  # Number of samples in a batch\n",
    "modality_1 = torch.randn(batch_size, input_dims[0])  # First modality with input dimension 64\n",
    "modality_2 = torch.randn(batch_size, input_dims[1])  # Second modality with input dimension 128\n",
    "modality_3 = torch.randn(batch_size, input_dims[2])  # Third modality with input dimension 256\n",
    "\n",
    "# Combine modalities into a list and pass through the model\n",
    "input_data = [modality_1, modality_2, modality_3]\n",
    "output = model(input_data)\n",
    "\n",
    "# Print output shape to verify\n",
    "print(\"Output shape:\", output.shape)  # Expected shape: [batch_size, output_dim]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-1.0926],\n",
      "        [-1.1314],\n",
      "        [-1.0889],\n",
      "        [-1.1205],\n",
      "        [-1.0704],\n",
      "        [-1.0984],\n",
      "        [-1.0807],\n",
      "        [-1.0941],\n",
      "        [-1.1047],\n",
      "        [-1.1045]], grad_fn=<AddmmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/5], Loss: 2.0485\n",
      "Epoch [2/5], Loss: 16.5415\n",
      "Epoch [3/5], Loss: 3.2676\n",
      "Epoch [4/5], Loss: 1.2193\n",
      "Epoch [5/5], Loss: 2.2094\n"
     ]
    }
   ],
   "source": [
    "# Dummy target output (regression target)\n",
    "target = torch.randn(batch_size, 1)  # Shape: [batch_size, output_dim]\n",
    "\n",
    "learning_rate = 0.001\n",
    "num_epochs = 5\n",
    "# Define loss function and optimizer\n",
    "criterion = nn.MSELoss()  # Mean Squared Error for regression\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(num_epochs):\n",
    "    # Zero the parameter gradients\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    # Forward pass\n",
    "    inputs = [modality_1, modality_2, modality_3]\n",
    "    output = model(inputs)\n",
    "    \n",
    "    # Compute loss\n",
    "    loss = criterion(output, target)\n",
    "    \n",
    "    # Backward pass and optimize\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    # Print loss\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(768, 1)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "arr = np.load('/home/hice1/mbibars3/scratch/vlm-debiasing/data/e-daic/untarred/717_P/717_AUDIO_ast9_pooled.npy')\n",
    "arr.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example training the model using the dataloader"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building the dataloader with dummy multimodal data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following cell is optional to create and save dummy multimodal data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```py\n",
    "# Define paths for saving the dummy data\n",
    "os.makedirs(\"../dummy_data\", exist_ok=True)\n",
    "\n",
    "# Generate dummy data and save it to .npy files\n",
    "num_samples = 10\n",
    "feature_size = 5\n",
    "\n",
    "data = {\n",
    "    \"label\": [],\n",
    "    \"modality1_path\": [],\n",
    "    \"modality2_path\": [],\n",
    "    \"modality3_path\": []\n",
    "}\n",
    "\n",
    "for i in range(num_samples):\n",
    "    # Create dummy numpy arrays of shape (feature, 1)\n",
    "    modality1 = np.random.rand(feature_size, 1)\n",
    "    modality2 = np.random.rand(feature_size, 1)\n",
    "    modality3 = np.random.rand(feature_size, 1)\n",
    "\n",
    "    # Save each modality to a separate file\n",
    "    modality1_path = f\"../dummy_data/modality1_sample{i}.npy\"\n",
    "    modality2_path = f\"../dummy_data/modality2_sample{i}.npy\"\n",
    "    modality3_path = f\"../dummy_data/modality3_sample{i}.npy\"\n",
    "    np.save(modality1_path, modality1)\n",
    "    np.save(modality2_path, modality2)\n",
    "    np.save(modality3_path, modality3)\n",
    "    \n",
    "    # Populate data for the DataFrame\n",
    "    data[\"label\"].append(np.random.randint(0, 2))  # Random label (0 or 1)\n",
    "    data[\"modality1_path\"].append(modality1_path)\n",
    "    data[\"modality2_path\"].append(modality2_path)\n",
    "    data[\"modality3_path\"].append(modality3_path)\n",
    "\n",
    "# Create the DataFrame\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Save the DataFrame to a CSV\n",
    "df.to_csv(\"../dummy_data/data.csv\", index=False)\n",
    "\n",
    "print(\"Dummy data created and saved to 'dummy_data' folder.\")\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>modality1_path</th>\n",
       "      <th>modality2_path</th>\n",
       "      <th>modality3_path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>../dummy_data/modality1_sample0.npy</td>\n",
       "      <td>../dummy_data/modality2_sample0.npy</td>\n",
       "      <td>../dummy_data/modality3_sample0.npy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>../dummy_data/modality1_sample1.npy</td>\n",
       "      <td>../dummy_data/modality2_sample1.npy</td>\n",
       "      <td>../dummy_data/modality3_sample1.npy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>../dummy_data/modality1_sample2.npy</td>\n",
       "      <td>../dummy_data/modality2_sample2.npy</td>\n",
       "      <td>../dummy_data/modality3_sample2.npy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>../dummy_data/modality1_sample3.npy</td>\n",
       "      <td>../dummy_data/modality2_sample3.npy</td>\n",
       "      <td>../dummy_data/modality3_sample3.npy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>../dummy_data/modality1_sample4.npy</td>\n",
       "      <td>../dummy_data/modality2_sample4.npy</td>\n",
       "      <td>../dummy_data/modality3_sample4.npy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>../dummy_data/modality1_sample5.npy</td>\n",
       "      <td>../dummy_data/modality2_sample5.npy</td>\n",
       "      <td>../dummy_data/modality3_sample5.npy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>../dummy_data/modality1_sample6.npy</td>\n",
       "      <td>../dummy_data/modality2_sample6.npy</td>\n",
       "      <td>../dummy_data/modality3_sample6.npy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>../dummy_data/modality1_sample7.npy</td>\n",
       "      <td>../dummy_data/modality2_sample7.npy</td>\n",
       "      <td>../dummy_data/modality3_sample7.npy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>../dummy_data/modality1_sample8.npy</td>\n",
       "      <td>../dummy_data/modality2_sample8.npy</td>\n",
       "      <td>../dummy_data/modality3_sample8.npy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>../dummy_data/modality1_sample9.npy</td>\n",
       "      <td>../dummy_data/modality2_sample9.npy</td>\n",
       "      <td>../dummy_data/modality3_sample9.npy</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label                       modality1_path  \\\n",
       "0      1  ../dummy_data/modality1_sample0.npy   \n",
       "1      0  ../dummy_data/modality1_sample1.npy   \n",
       "2      1  ../dummy_data/modality1_sample2.npy   \n",
       "3      0  ../dummy_data/modality1_sample3.npy   \n",
       "4      0  ../dummy_data/modality1_sample4.npy   \n",
       "5      1  ../dummy_data/modality1_sample5.npy   \n",
       "6      0  ../dummy_data/modality1_sample6.npy   \n",
       "7      1  ../dummy_data/modality1_sample7.npy   \n",
       "8      1  ../dummy_data/modality1_sample8.npy   \n",
       "9      1  ../dummy_data/modality1_sample9.npy   \n",
       "\n",
       "                        modality2_path                       modality3_path  \n",
       "0  ../dummy_data/modality2_sample0.npy  ../dummy_data/modality3_sample0.npy  \n",
       "1  ../dummy_data/modality2_sample1.npy  ../dummy_data/modality3_sample1.npy  \n",
       "2  ../dummy_data/modality2_sample2.npy  ../dummy_data/modality3_sample2.npy  \n",
       "3  ../dummy_data/modality2_sample3.npy  ../dummy_data/modality3_sample3.npy  \n",
       "4  ../dummy_data/modality2_sample4.npy  ../dummy_data/modality3_sample4.npy  \n",
       "5  ../dummy_data/modality2_sample5.npy  ../dummy_data/modality3_sample5.npy  \n",
       "6  ../dummy_data/modality2_sample6.npy  ../dummy_data/modality3_sample6.npy  \n",
       "7  ../dummy_data/modality2_sample7.npy  ../dummy_data/modality3_sample7.npy  \n",
       "8  ../dummy_data/modality2_sample8.npy  ../dummy_data/modality3_sample8.npy  \n",
       "9  ../dummy_data/modality2_sample9.npy  ../dummy_data/modality3_sample9.npy  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"../dummy_data/data.csv\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modality 1 shape: torch.Size([2, 5, 1])\n",
      "Modality 2 shape: torch.Size([2, 5, 1])\n",
      "Modality 3 shape: torch.Size([2, 5, 1])\n",
      "Labels shape: tensor([1., 0.])\n",
      "Modality 1 shape: torch.Size([2, 5, 1])\n",
      "Modality 2 shape: torch.Size([2, 5, 1])\n",
      "Modality 3 shape: torch.Size([2, 5, 1])\n",
      "Labels shape: tensor([1., 0.])\n",
      "Modality 1 shape: torch.Size([2, 5, 1])\n",
      "Modality 2 shape: torch.Size([2, 5, 1])\n",
      "Modality 3 shape: torch.Size([2, 5, 1])\n",
      "Labels shape: tensor([0., 1.])\n",
      "Modality 1 shape: torch.Size([2, 5, 1])\n",
      "Modality 2 shape: torch.Size([2, 5, 1])\n",
      "Modality 3 shape: torch.Size([2, 5, 1])\n",
      "Labels shape: tensor([0., 1.])\n",
      "Modality 1 shape: torch.Size([2, 5, 1])\n",
      "Modality 2 shape: torch.Size([2, 5, 1])\n",
      "Modality 3 shape: torch.Size([2, 5, 1])\n",
      "Labels shape: tensor([1., 1.])\n"
     ]
    }
   ],
   "source": [
    "dataset = loaders.MultiModalityDataset(df, modalities = {\"modality1_path\", \"modality2_path\", \"modality3_path\"})\n",
    "dataloader = DataLoader(dataset, batch_size=2, collate_fn=loaders.collate_fn)\n",
    "\n",
    "for batch in dataloader:\n",
    "    modalities, labels = batch\n",
    "    print(f\"Modality 1 shape: {modalities[0].shape}\")  # Expected shape: (batch_size, feature, 1)\n",
    "    print(f\"Modality 2 shape: {modalities[1].shape}\")\n",
    "    print(f\"Modality 3 shape: {modalities[2].shape}\")\n",
    "    print(f\"Labels shape: {labels}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define input dimensions for each modality\n",
    "input_dims = [5, 5, 5]  # These are the feature dimensions for each modality\n",
    "\n",
    "# Initialize MultiModalPerceiver model\n",
    "model = m.MultiModalPerceiver(\n",
    "    input_dims=input_dims,\n",
    "    input_channels=1,\n",
    "    input_axis=1,\n",
    "    projection_dim=256,\n",
    "    num_latents=16,\n",
    "    latent_dim=128,\n",
    "    depth=8,\n",
    "    cross_heads=8,\n",
    "    latent_heads=8,\n",
    "    cross_dim_head=32,\n",
    "    latent_dim_head=32,\n",
    "    attn_dropout=0.1,\n",
    "    ff_dropout=0.0,\n",
    "    output_dim=1,\n",
    "    weight_tie_layers=True,\n",
    "    fourier_encode_data=False,\n",
    "    max_freq=10,\n",
    "    num_freq_bands=4\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'nn' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m num_epochs \u001b[39m=\u001b[39m \u001b[39m5\u001b[39m\n\u001b[1;32m      3\u001b[0m \u001b[39m# Define loss function and optimizer\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m criterion \u001b[39m=\u001b[39m nn\u001b[39m.\u001b[39mMSELoss()  \u001b[39m# Mean Squared Error for regression\u001b[39;00m\n\u001b[1;32m      5\u001b[0m optimizer \u001b[39m=\u001b[39m optim\u001b[39m.\u001b[39mAdam(model\u001b[39m.\u001b[39mparameters(), lr\u001b[39m=\u001b[39mlearning_rate)\n\u001b[1;32m      7\u001b[0m \u001b[39m# Training loop\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'nn' is not defined"
     ]
    }
   ],
   "source": [
    "learning_rate = 0.001\n",
    "num_epochs = 5\n",
    "# Define loss function and optimizer\n",
    "criterion = nn.MSELoss()  # Mean Squared Error for regression\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(num_epochs):\n",
    "    for batch in dataloader:\n",
    "        # Unpack the batch\n",
    "        modalities, labels = batch\n",
    "        modality_1, modality_2, modality_3 = modalities  # Each has shape (batch_size, feature, 1)\n",
    "\n",
    "        # Zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward pass\n",
    "        inputs = [modality_1, modality_2, modality_3]\n",
    "        output = model(inputs)\n",
    "\n",
    "        #print(output, labels)\n",
    "        # Reshape labels to match the output shape if necessary\n",
    "        labels = labels.view(output.shape)  # Ensures labels has shape (batch_size, 1)\n",
    "\n",
    "        # Compute loss\n",
    "        loss = criterion(output, labels)\n",
    "\n",
    "        # Backward pass and optimize\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Print loss\n",
    "        print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
